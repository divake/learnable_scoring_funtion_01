# AG News specific configuration
inherit: base_config.yaml

# Device configuration
device: 0  # Use first GPU (cuda:0)
multi_gpu: true  # Enable multi-GPU training with DataParallel

dataset:
  name: gpt_ag_news
  num_classes: 4  # AG News has 4 classes (0, 1, 2, 3)
  feature_dir: "/ssd_4TB/divake/LLM_VLM/data"
  feature_dim: 768  # GPT embeddings dimension
  use_logits: false  # Set to true if you want to use logits instead of embeddings

# Paths
plot_dir: plots/gpt_ag_news
log_dir: logs/gpt_ag_news

# Training parameters - adjusted for balanced approach
num_epochs: 100
batch_size: 128
learning_rate: 0.0003
lambda1: 2.0  # Coverage loss weight
lambda2: 1.0  # Set size loss weight
target_coverage: 0.9  # Standard target coverage

# Training configuration
training:
  grad_clip:
    enabled: true
    max_norm: 0.5
  loss_weights:
    coverage: 2.0  # Match lambda1
    size: 1.0  # Match lambda2
    margin: 0.3  # Reduced margin weight

# Optimizer configuration
optimizer:
  name: 'AdamW'
  params:
    lr: 0.0003  # Match learning_rate
    weight_decay: 0.003
  scheduler:
    name: 'OneCycleLR'
    params:
      max_lr: 0.001
      pct_start: 0.3
      div_factor: 10
      final_div_factor: 50
      anneal_strategy: 'cos'

# Model architecture - minimal changes to avoid affecting core code
scoring_function:
  hidden_dims: [64, 32]  # Simplified architecture
  dropout: 0.2  # Moderate dropout
  l2_lambda: 0.005  # Moderate regularization
  activation:
    name: 'LeakyReLU'
    params:
      negative_slope: 0.1
  final_activation:
    name: 'Softplus'
    params:
      beta: 2  # Moderate sharpness

# Training constraints - adjusted based on test results
tau:
  min: 0.64  # Just above true class score mean (0.6249)
  max: 0.67  # Just below false class score mean (0.6720)
  window_size: 5  # Increased for more stable tau

# Set size constraints - adjusted for AG News dataset
set_size:
  target: 1.2  # Target slightly more than 1 class per prediction
  max: 2.0  # Maximum of 2 classes (out of 4)
  margin: 0.6  